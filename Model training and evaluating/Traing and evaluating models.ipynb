{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import required packages\n",
    "#from tensorflow.python.keras import backend as K\n",
    "import keras\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "from keras import backend\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import fmin, tpe, hp,rand, space_eval\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#define the model creating method and relevent metric r2\n",
    "def r2(y_true, y_pred):\n",
    "    SSE = backend.sum(backend.square(y_pred - y_true))\n",
    "    SST = backend.sum(backend.square(y_true-backend.mean(y_true)))\n",
    "    r2 = 1-SSE/SST\n",
    "    return r2\n",
    "\n",
    "def create_model(input_length, hyperparameter):\n",
    "    num_dense_layers = hyperparameter[0]\n",
    "    num_dense_nodes = hyperparameter[1]\n",
    "    activation = hyperparameter[2]\n",
    "    learning_rate = hyperparameter[3]\n",
    "    adam_decay = hyperparameter[4]\n",
    "    drop_out = hyperparameter[5]\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=[input_length, 1]))\n",
    "\n",
    "    for i in range(int(num_dense_layers)):\n",
    "        name = 'layer_dense_{0}'.format(i + 1)\n",
    "        model.add(Dense(num_dense_nodes, activation=activation, name=name ))\n",
    "        model.add(Dropout(drop_out)),\n",
    "\n",
    "    opt = Adam(learning_rate=learning_rate, decay=adam_decay)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss=\"mse\",optimizer=opt, metrics=['mse',r2])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# define the optimization function\n",
    "def fitness(parameters):\n",
    "    hyperparameter = [int(parameters[\"num_dense_layers\"]), int(parameters[\"num_dense_nodes\"]),\n",
    "                        parameters[\"activation\"], parameters[\"learning_rate\"],\n",
    "                      parameters[\"adam_decay\"],parameters[\"drop_out\"]]\n",
    "    input_length = len(train_feature[0])\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_tot_pred = []\n",
    "    test_tot_real = []\n",
    "    for train, test in kfold.split(train_feature, train_output):\n",
    "        model = create_model(input_length, hyperparameter)\n",
    "        Scaler = MinMaxScaler()\n",
    "        Scaler.fit(train_feature[train])\n",
    "        Trains = Scaler.transform(train_feature[train])\n",
    "        Tests = Scaler.transform(train_feature[test])\n",
    "        Trains = np.reshape(Trains, (len(Trains), input_length, 1))\n",
    "        Tests = np.reshape(Tests, (len(Tests), input_length, 1))\n",
    "        model.fit(Trains,train_output[train], batch_size=200, epochs=50, verbose=0)\n",
    "        test_tot_pred = np.append(test_tot_pred, model.predict(Tests))\n",
    "        test_tot_real = np.append(test_tot_real, train_output[test])\n",
    "        del model\n",
    "        keras.backend.clear_session()\n",
    "        ops.reset_default_graph()\n",
    "    MSE = mean_squared_error(test_tot_real,test_tot_pred)\n",
    "    r2 = r2_score(test_tot_real,test_tot_pred)\n",
    "    global parameter_inputs\n",
    "    parameter_input_values = parameters\n",
    "    parameter_input = pd.DataFrame(parameter_input_values, index=[0])\n",
    "    parameter_input[\"mse_train\"] = MSE\n",
    "    parameter_input[\"r2_train\"] = r2\n",
    "    parameter_inputs = parameter_inputs.append(parameter_input, sort=False)\n",
    "    parameter_inputs.to_csv(save_path)\n",
    "\n",
    "    print()\n",
    "    print(\"MSE:{:.2f}, R2:{:.2f}, HidLays:{}, NNeurons:{}\".format(MSE, r2, hyperparameter[0],hyperparameter[1]))\n",
    "    print()\n",
    "    return MSE\n",
    "\n",
    "space={'learning_rate': hp.loguniform('learning_rate', np.log(1e-6),np.log(1e-2)),\n",
    "    'num_dense_layers': hp.quniform('num_dense_layers', 1, 3, 1),\n",
    "    'num_dense_nodes': hp.quniform('num_dense_nodes', 20, 2048, 2),\n",
    "    'activation': hp.choice('activation', ['relu', 'selu', 'sigmoid', 'linear']),\n",
    "    'adam_decay': hp.loguniform('adam_decay', np.log(1e-6), np.log(1e-2)),\n",
    "    'drop_out': hp.uniform('drop_out', 0, 0.5)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018671412809133554                                  \n",
      "0.9686831748553386                                    \n",
      "MSE:0.02, R2:0.97, HidLays:3, NNeurons:442            \n",
      "0.05201525983761111                                                               \n",
      "0.9127568538149531                                                                \n",
      "MSE:0.05, R2:0.91, HidLays:1, NNeurons:1790                                       \n",
      "0.04747410814310304                                                               \n",
      "0.9203735486535314                                                                \n",
      "MSE:0.05, R2:0.92, HidLays:2, NNeurons:124                                        \n",
      "0.018420913630056573                                                              \n",
      "0.969103327259992                                                                 \n",
      "MSE:0.02, R2:0.97, HidLays:2, NNeurons:972                                        \n",
      "0.019639552338093582                                                              \n",
      "0.9670593525632598                                                                \n",
      "MSE:0.02, R2:0.97, HidLays:3, NNeurons:1932                                       \n",
      "0.06665623155284255                                                               \n",
      "0.888200128737912                                                                 \n",
      "MSE:0.07, R2:0.89, HidLays:1, NNeurons:420                                        \n",
      "0.016671877168030803                                                              \n",
      "0.972036917214476                                                                 \n",
      "MSE:0.02, R2:0.97, HidLays:2, NNeurons:1078                                       \n",
      "0.020724596142896144                                                              \n",
      "0.965239451334753                                                                 \n",
      "MSE:0.02, R2:0.97, HidLays:2, NNeurons:1420                                       \n",
      "0.03716810843637535                                                               \n",
      "0.9376593959568827                                                                \n",
      "MSE:0.04, R2:0.94, HidLays:2, NNeurons:958                                        \n",
      "0.01962328988334948                                                               \n",
      "0.9670866289379428                                                                \n",
      "MSE:0.02, R2:0.97, HidLays:1, NNeurons:382                                        \n",
      "100%|██████████| 10/10 [09:37<00:00, 57.72s/trial, best loss: 0.016671877168030803]\n",
      "0.3739833157776845                                    \n",
      "0.009677794956859942                                  \n",
      "MSE:0.37, R2:0.01, HidLays:2, NNeurons:1732           \n",
      "0.1665566280109387                                                               \n",
      "0.5589516426064451                                                               \n",
      "MSE:0.17, R2:0.56, HidLays:1, NNeurons:332                                       \n",
      "0.061279523958005094                                                             \n",
      "0.8377294635085786                                                              \n",
      "MSE:0.06, R2:0.84, HidLays:2, NNeurons:1776                                     \n",
      "0.06453887656262573                                                               \n",
      "0.8290985724440697                                                                \n",
      "MSE:0.06, R2:0.83, HidLays:2, NNeurons:1886                                       \n",
      "0.08983231935891324                                                               \n",
      "0.7621205630345744                                                                \n",
      "MSE:0.09, R2:0.76, HidLays:2, NNeurons:1116                                       \n",
      "0.09306019214230092                                                               \n",
      "0.7535730317475278                                                                \n",
      "MSE:0.09, R2:0.75, HidLays:3, NNeurons:338                                        \n",
      "0.3696969676695765                                                                \n",
      "0.021028209616874682                                                              \n",
      "MSE:0.37, R2:0.02, HidLays:3, NNeurons:706                                        \n",
      "0.060729212557857744                                                              \n",
      "0.8391867092633016                                                                \n",
      "MSE:0.06, R2:0.84, HidLays:2, NNeurons:1752                                       \n",
      "0.41407565022201437                                                               \n",
      "-0.09648824876001583                                                              \n",
      "MSE:0.41, R2:-0.10, HidLays:2, NNeurons:1046                                      \n",
      "0.06157168587319292                                                               \n",
      "0.8369558075194691                                                                \n",
      "MSE:0.06, R2:0.84, HidLays:2, NNeurons:510                                        \n",
      "100%|██████████| 10/10 [11:14<00:00, 67.49s/trial, best loss: 0.060729212557857744]\n",
      "0.06870054244522575                                   \n",
      "0.049518811978092714                                  \n",
      "MSE:0.07, R2:0.05, HidLays:3, NNeurons:1154           \n",
      "0.026463668082657342                                                             \n",
      "0.633871614642985                                                                \n",
      "MSE:0.03, R2:0.63, HidLays:2, NNeurons:508                                       \n",
      "0.3470103640220935                                                                \n",
      "-3.800934771579156                                                                \n",
      "MSE:0.35, R2:-3.80, HidLays:2, NNeurons:1826                                      \n",
      "0.04462808584158167                                                               \n",
      "0.38256446688656387                                                               \n",
      "MSE:0.04, R2:0.38, HidLays:1, NNeurons:36                                         \n",
      "0.012150372551640238                                                              \n",
      "0.8318979715917171                                                                \n",
      "MSE:0.01, R2:0.83, HidLays:1, NNeurons:482                                        \n",
      "0.014086408964774345                                                              \n",
      "0.8051126490234634                                                                \n",
      "MSE:0.01, R2:0.81, HidLays:2, NNeurons:962                                        \n",
      "0.012676286325980765                                                              \n",
      "0.8246218842241273                                                                \n",
      "MSE:0.01, R2:0.82, HidLays:2, NNeurons:488                                        \n",
      "0.013306828629549426                                                              \n",
      "0.8158982471688327                                                                \n",
      "MSE:0.01, R2:0.82, HidLays:1, NNeurons:598                                        \n",
      "0.1736907872831561                                                                \n",
      "-1.4030352595393123                                                               \n",
      "MSE:0.17, R2:-1.40, HidLays:2, NNeurons:328                                       \n",
      "0.03384851942213785                                                               \n",
      "0.5317012092184439                                                                \n",
      "MSE:0.03, R2:0.53, HidLays:1, NNeurons:1578                                       \n",
      "100%|██████████| 10/10 [07:03<00:00, 42.38s/trial, best loss: 0.012150372551640238]\n",
      "0.025932749640104055                                  \n",
      "0.8748231494227963                                    \n",
      "MSE:0.03, R2:0.87, HidLays:1, NNeurons:152            \n",
      "0.16016605235484707                                                               \n",
      "0.2268817506278581                                                                \n",
      "MSE:0.16, R2:0.23, HidLays:2, NNeurons:1996                                       \n",
      "0.207470350772485                                                                 \n",
      "-0.0014551275228060767                                                            \n",
      "MSE:0.21, R2:-0.00, HidLays:3, NNeurons:1526                                      \n",
      "0.03815364890184791                                                                \n",
      "0.8158331193628665                                                                 \n",
      "MSE:0.04, R2:0.82, HidLays:1, NNeurons:684                                         \n",
      "0.05913842369838489                                                                \n",
      "0.7145400418621252                                                                 \n",
      "MSE:0.06, R2:0.71, HidLays:2, NNeurons:1554                                        \n",
      "0.01786702992131994                                                                \n",
      "0.9137562130603857                                                                 \n",
      "MSE:0.02, R2:0.91, HidLays:2, NNeurons:636                                         \n",
      "0.018532938666650824                                                               \n",
      "0.9105418852058711                                                               \n",
      "MSE:0.02, R2:0.91, HidLays:1, NNeurons:1124                                      \n",
      "0.02685462647166961                                                              \n",
      "0.8703732688664741                                                               \n",
      "MSE:0.03, R2:0.87, HidLays:2, NNeurons:1604                                      \n",
      "0.018621315429033287                                                             \n",
      "0.9101152923866455                                                               \n",
      "MSE:0.02, R2:0.91, HidLays:3, NNeurons:224                                       \n",
      "0.028138169138538345                                                             \n",
      "0.8641776347416753                                                               \n",
      "MSE:0.03, R2:0.86, HidLays:2, NNeurons:1226                                      \n",
      "100%|██████████| 10/10 [12:48<00:00, 76.84s/trial, best loss: 0.01786702992131994]\n"
     ]
    }
   ],
   "source": [
    "Sourcepath =os.path.join(\"./source_data.csv\")\n",
    "source_data= pd.read_csv(Sourcepath)\n",
    "train_data,test_data  = train_test_split(source_data,test_size=0.2)\n",
    "train_input = train_data.iloc[:, 10:].dropna(axis='columns')\n",
    "for OutputIndex in [\"E\", \"S\", \"A\", \"B\"]:\n",
    "    train_feature = train_input.values\n",
    "    train_output = train_data[OutputIndex].values\n",
    "    save_path = \"./\"+OutputIndex+\"_\"+\"PaDEL_hyperparameters.csv\"\n",
    "    parameter_inputs = pd.DataFrame({\"num_dense_layers\":[],\"num_dense_nodes\":[]\n",
    "                     ,\"learning_rate\":[],\"activation\":[]\n",
    "                     ,\"adam_decay\":[],\"mse_train\":[],\"r2_train\":[]})\n",
    "    best = fmin(fitness, space=space, algo=tpe.suggest, max_evals=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}